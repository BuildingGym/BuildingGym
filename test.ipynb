{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /home/user@AD/lab/EnergyPlus-OOEP\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: energyplus-core in ./.venv/lib/python3.11/site-packages (from energyplus-ooep==0.0.post1.dev14+g65437eb.d20240408) (0.1.0a0)\n",
      "Building wheels for collected packages: energyplus-ooep\n",
      "  Building wheel for energyplus-ooep (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for energyplus-ooep: filename=energyplus_ooep-0.0.post1.dev14+g65437eb.d20240408-py3-none-any.whl size=26528 sha256=c6787b2b78a4e8132dbc6a1e9e408154a91933a3d81ade511629f44dbbf92d90\n",
      "  Stored in directory: /home/user@AD/.cache/pip/wheels/16/f9/7c/4f4cbae4f9bac45a57e6927307e3d5abdc8afb7240c9c634ff\n",
      "Successfully built energyplus-ooep\n",
      "Installing collected packages: energyplus-ooep\n",
      "  Attempting uninstall: energyplus-ooep\n",
      "    Found existing installation: energyplus-ooep 0.0.post1.dev14+g65437eb.d20240404\n",
      "    Uninstalling energyplus-ooep-0.0.post1.dev14+g65437eb.d20240404:\n",
      "      Successfully uninstalled energyplus-ooep-0.0.post1.dev14+g65437eb.d20240404\n",
      "Successfully installed energyplus-ooep-0.0.post1.dev14+g65437eb.d20240408\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install ../../lab/EnergyPlus-OOEP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pyenergyplus'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mepluspy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m idf_editor\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mepluspy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m idf_simu\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01menergyplus\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mooep\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01maddons\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlogging\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LogProvider\n",
      "File \u001b[0;32m~/lab/EnergyGym/epluspy/idf_editor.py:5\u001b[0m\n\u001b[1;32m      3\u001b[0m sys\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC:/EnergyPlusV9-4-0\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyenergyplus\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m EnergyPlusAPI\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjson\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdatetime\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m datetime\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pyenergyplus'"
     ]
    }
   ],
   "source": [
    "from epluspy import idf_editor\n",
    "from epluspy import idf_simu\n",
    "\n",
    "import energyplus.ooep as _ooep_\n",
    "import gymnasium as _gymnasium_\n",
    "import numpy as _numpy_\n",
    "import energyplus.ooep.addons\n",
    "from energyplus.ooep.components.variables import (\n",
    "    Actuator,\n",
    "    OutputVariable,\n",
    ")\n",
    "import logging\n",
    "from energyplus.ooep.addons.logging import LogProvider\n",
    "from energyplus.dataset.basic import dataset as _epds_\n",
    "from energyplus.ooep.addons.rl.gymnasium.spaces import VariableBox\n",
    "from energyplus.ooep.addons.display import ProgressProvider\n",
    "from energyplus.ooep import (\n",
    "    Simulator,\n",
    "    Model,\n",
    "    Weather,\n",
    "    Report,\n",
    ")\n",
    "import asyncio\n",
    "from energyplus.ooep.addons.rl.gymnasium import ThinEnv\n",
    "\n",
    "import os\n",
    "import json\n",
    "from hyper_para.dqn_para import Args\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import tyro\n",
    "import random\n",
    "import time\n",
    "from stable_baselines3.common.buffers import ReplayBuffer\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from gymnasium.spaces import Box\n",
    "from gymnasium.spaces import Discrete\n",
    "import wandb\n",
    "import math\n",
    "import pandas as pd\n",
    "\n",
    "# ALGO LOGIC: initialize agent here:\n",
    "class QNetwork(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super().__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Linear(input_dim, 120),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(120, 84),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(84, output_dim),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.network(x)\n",
    "    \n",
    "class dqn():\n",
    "    def __init__(self, idf_env, input_var, q_network, target_network) -> None:\n",
    "        self.idf_env = idf_env\n",
    "        self.run_name = f\"{args.env_id}__{args.exp_name}__{args.seed}__{int(time.time())}\"\n",
    "        self.input_var = input_var\n",
    "        self.obs_index = []\n",
    "        self.q_network = q_network\n",
    "        self.target_network = target_network\n",
    "        self.writer = SummaryWriter(f\"runs/{self.run_name}\")\n",
    "        self.writer.add_text(\n",
    "            \"hyperparameters\",\n",
    "            \"|param|value|\\n|-|-|\\n%s\" % (\"\\n\".join([f\"|{key}|{value}|\" for key, value in vars(args).items()])))\n",
    "        \n",
    "    def train(self):\n",
    "        if args.track:\n",
    "            self.call_track()\n",
    "        # TRY NOT TO MODIFY: seeding\n",
    "        random.seed(args.seed)\n",
    "        np.random.seed(args.seed)\n",
    "        torch.manual_seed(args.seed)\n",
    "        torch.backends.cudnn.deterministic = args.torch_deterministic\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() and args.cuda else \"cpu\")\n",
    "\n",
    "        rb = ReplayBuffer(\n",
    "            args.buffer_size,\n",
    "            Box(np.array([-1] * args.input_dim), np.array([1] * args.input_dim)),\n",
    "            Discrete(args.output_dim),\n",
    "            device,\n",
    "            handle_timeout_termination=False,\n",
    "        )\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # TRY NOT TO MODIFY: start the game\n",
    "        for global_step in range(args.total_timesteps):\n",
    "            if args.track:\n",
    "                wandb.log({'random_curve':global_step/100+random.random()},step=global_step)\n",
    "                wandb.log({'log_curve': math.log(global_step+1)},step=global_step)        \n",
    "            # ALGO LOGIC: put action logic here\n",
    "            epsilon = linear_schedule(args.start_e, args.end_e, args.exploration_fraction * args.total_timesteps, global_step)\n",
    "            # if random.random() < epsilon:\n",
    "            #     actions = np.array([envs.single_action_space.sample() for _ in range(envs.num_envs)])\n",
    "            # else:\n",
    "            #     q_values = q_network(torch.Tensor(obs).to(device))\n",
    "            #     actions = torch.argmax(q_values, dim=1).cpu().numpy()\n",
    "\n",
    "            epsilon = linear_schedule(args.start_e, args.end_e,\n",
    "                                      args.exploration_fraction * args.total_timesteps,\n",
    "                                      global_step)\n",
    "            myidf.run(epsilon = epsilon)\n",
    "            self.label_working_time()\n",
    "            self.cal_r()\n",
    "            myidf.save()\n",
    "            if len(self.obs_index) == 0:\n",
    "                sensor_name_list = list(myidf.sensor_dic.columns)\n",
    "                for i in self.input_var:\n",
    "                    assert i in sensor_name_list, \"The input variable is not in the sensor list, please add it\"\n",
    "                    self.obs_index.append(sensor_name_list.index(i))\n",
    "            for i in range(myidf.sensor_dic.shape[0]-1):\n",
    "                obs = myidf.sensor_dic.iloc[i,self.obs_index]\n",
    "                next_obs = myidf.sensor_dic.iloc[i+1,self.obs_index]\n",
    "                rewards = myidf.sensor_dic.iloc[i, list(myidf.sensor_dic.columns).index('reward' )]\n",
    "                actions = myidf.action_dic.iloc[i, 0]\n",
    "                if myidf.sensor_dic['Working_time'][i]:\n",
    "                    rb.add(np.array(obs),\n",
    "                        np.array(next_obs),\n",
    "                        np.array(actions),\n",
    "                        np.array(rewards),\n",
    "                        np.array([False]),\n",
    "                            '')\n",
    "            if global_step > args.learning_starts:\n",
    "                if global_step % args.train_frequency == 0:\n",
    "                    data = rb.sample(args.batch_size)\n",
    "                    with torch.no_grad():\n",
    "                        target_max, _ = self.target_network(data.next_observations).max(dim=1)\n",
    "                        td_target = data.rewards.flatten() + args.gamma * target_max\n",
    "                    old_val = self.q_network(data.observations).gather(1, data.actions).squeeze()\n",
    "                    loss = F.mse_loss(td_target, old_val)\n",
    "\n",
    "                    if global_step % 10 == 0:\n",
    "                        self.writer.add_scalar(\"losses/td_loss\", loss, global_step)\n",
    "                        self.writer.add_scalar(\"losses/q_values\", old_val.mean().item(), global_step)\n",
    "                        print(\"SPS:\", int(global_step / (time.time() - start_time)))\n",
    "                        self.writer.add_scalar(\"charts/SPS\", int(global_step / (time.time() - start_time)), global_step)\n",
    "\n",
    "                    # optimize the model\n",
    "                    optimizer.zero_grad()\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "                # update target network\n",
    "                if global_step % args.target_network_frequency == 0:\n",
    "                    for target_network_param, q_network_param in zip(self.target_network.parameters(), self.q_network.parameters()):\n",
    "                        target_network_param.data.copy_(\n",
    "                            args.tau * q_network_param.data + (1.0 - args.tau) * target_network_param.data\n",
    "                        )            \n",
    "\n",
    "    def call_track(self):\n",
    "        import wandb\n",
    "        wandb.init(\n",
    "            project=args.wandb_project_name,\n",
    "            entity=args.wandb_entity,\n",
    "            sync_tensorboard=True,\n",
    "            config=vars(args),\n",
    "            name=self.run_name,\n",
    "            # monitor_gym=True,\n",
    "            save_code=True,\n",
    "        )\n",
    "\n",
    "    def label_working_time(self):\n",
    "        start = pd.to_datetime(args.work_time_start, format='%H:%M')\n",
    "        end = pd.to_datetime(args.work_time_end, format='%H:%M')\n",
    "        # remove data without enough outlook step\n",
    "        dt = int(60/myidf.n_time_step) * args.outlook_step\n",
    "        dt = pd.to_timedelta(dt, unit='min')\n",
    "        end -= dt\n",
    "        wt = [] # wt: working time label\n",
    "        for i in range(int(myidf.sensor_dic.shape[0])):\n",
    "            h = myidf.sensor_dic['Time'][i].minute\n",
    "            m = myidf.sensor_dic['Time'][i].hour\n",
    "            t = pd.to_datetime(str(h)+':'+str(m), format='%M:%S')\n",
    "            if t >= start and t <= end:\n",
    "                wt.append(True)\n",
    "            else:\n",
    "                wt.append(False)\n",
    "        myidf.sensor_dic['Working_time'] = wt\n",
    "\n",
    "    def cal_r(self):\n",
    "        baseline = pd.read_csv('Data\\Day_mean.csv')\n",
    "        reward = []\n",
    "        for j in range(myidf.n_days+1):\n",
    "            for k in range(24*myidf.n_time_step):\n",
    "                reward_i = abs(myidf.sensor_dic['Chiller Electricity Rate@DOE REF 1980-2004 WATERCOOLED  CENTRIFUGAL CHILLER 0 1100TONS 0.7KW/TON'][j*24*myidf.n_time_step+k] - baseline['Day_mean'][k])\n",
    "                reward.append(reward_i)\n",
    "        # Realtime reward function\n",
    "        myidf.sensor_dic['reward'] = reward\n",
    "        # Return return function (future accmulated reward)\n",
    "        R_list = []\n",
    "        for i in range(myidf.sensor_dic.shape[0] - args.outlook_step):\n",
    "            reward_list = myidf.sensor_dic['reward'][i:(i+ args.outlook_step)]\n",
    "            R = 0\n",
    "            for r in reward_list[::-1]:\n",
    "                R = r + R * args.gamma\n",
    "            R_list.append(R)\n",
    "        \n",
    "        # Remove data without enough outlook steps\n",
    "        myidf.sensor_dic = myidf.sensor_dic[:-args.outlook_step]\n",
    "        if myidf.control:\n",
    "            myidf.cmd_dic = myidf.cmd_dic[:-args.outlook_step]\n",
    "            # append Return data\n",
    "        myidf.sensor_dic['Return'] = R_list\n",
    "    \n",
    "def linear_schedule(start_e: float, end_e: float, duration: int, t: int):\n",
    "    slope = (end_e - start_e) / duration\n",
    "    return max(slope * t + start_e, end_e)\n",
    "\n",
    "class ep_simu(idf_simu.IDF_simu):\n",
    "    def control_fun(self, senstor_t):\n",
    "        value = []\n",
    "        for i in range(len(self.input_var)):\n",
    "            value.append(list(senstor_t[self.input_var[i]])[0])\n",
    "        if random.random() < self.epsilon:\n",
    "            actions = random.sample(list(np.arange(0, 5)), 1)[0]\n",
    "        else:\n",
    "            q_values = self.agent(torch.Tensor(value).to(args.devices))\n",
    "            actions = torch.argmax(q_values, dim=0).cpu().numpy()\n",
    "        # com = [19 + actions]\n",
    "        com = [28]\n",
    "        return com, [actions]\n",
    "    \n",
    "async def energyplus_running(idf_file,epw_file):\n",
    "    await simulator.awaitable.run_forever(\n",
    "    input=Simulator.InputSpecs(\n",
    "        model=Model().open(\n",
    "            idf_file\n",
    "        ),\n",
    "        weather=Weather().open(epw_file),\n",
    "    ),\n",
    "    # output=Simulator.OutputSpecs(\n",
    "    #     report=Report().open('/tmp/ooep-report-9e1287d2-8e75-4cf5-bbc5-f76580b56a69'),\n",
    "    # ),\n",
    "    options=Simulator.RuntimeOptions(\n",
    "        #design_day=True,\n",
    "    ),\n",
    "    )\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    simulator = Simulator().add(\n",
    "    ProgressProvider(),\n",
    "    LogProvider(),\n",
    "    )\n",
    "    logging.basicConfig(level='INFO')\n",
    "    simulator.add(\n",
    "    thinenv := ThinEnv(\n",
    "        action_space=_gymnasium_.spaces.Dict({\n",
    "                    'thermostat': VariableBox(\n",
    "                        low=15., high=16.,\n",
    "                        dtype=_numpy_.float32,\n",
    "                        shape=(),\n",
    "                    ).bind(Actuator.Ref(\n",
    "                        type='Zone Temperature Control',\n",
    "                        control_type='Heating Setpoint',\n",
    "                        key='CORE_MID',\n",
    "                    ))\n",
    "                }),    \n",
    "        observation_space=_gymnasium_.spaces.Dict({\n",
    "            'temperature': VariableBox(\n",
    "                low=-_numpy_.inf, high=+_numpy_.inf,\n",
    "                dtype=_numpy_.float32,\n",
    "                shape=(),\n",
    "            ).bind(OutputVariable.Ref(\n",
    "                type='People Air Temperature',\n",
    "                key='CORE_MID',\n",
    "            )),\n",
    "        }),\n",
    "    )\n",
    "    )\n",
    "  \n",
    "    \n",
    "    \n",
    "\n",
    "    run_baseline = True\n",
    "    idf_file = 'Large office - 1AV940.idf'\n",
    "    epw_file = 'USA_FL_Miami.722020_TMY2.epw'\n",
    "    output_path = 'test\\\\'\n",
    "    epjson = 'C:\\\\EnergyPlusV9-4-0\\\\Energy+.schema.epJSON'\n",
    "    args = tyro.cli(Args)\n",
    "    q_network = QNetwork(args.input_dim, args.output_dim)\n",
    "    optimizer = optim.Adam(q_network.parameters(), lr=args.learning_rate)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() and args.cuda else \"cpu\")\n",
    "    target_network = QNetwork(args.input_dim, args.output_dim).to(device)\n",
    "    target_network.load_state_dict(q_network.state_dict())\n",
    "    input_var = ['Site Outdoor Air Drybulb Temperature@Environment',\n",
    "                  'Zone Mean Air Temperature@CORE_BOTTOM ZN',\n",
    "                  'Zone People Sensible Heating Rate@CORE_BOTTOM ZN']\n",
    "    # TO ADD: CHECK input_var\n",
    "    with open(epjson, 'r') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    loop = asyncio.get_running_loop()\n",
    "    task = loop.create_task(energyplus_running(idf_file = idf_file,\n",
    "                                               epw_file = epw_file))\n",
    "    myidf = ep_simu(idf_file, epw_file, output_path, '2018-08-01', '2018-08-31', 6, True, True, 5)\n",
    "    if run_baseline:\n",
    "        myidf.edit('Thermostatsetpoint:dualsetpoint', 'All', cooling_setpoint_temperature_schedule_name = 'Large Office ClgSetp')\n",
    "    else:\n",
    "        myidf.edit('Thermostatsetpoint:dualsetpoint', 'All', cooling_setpoint_temperature_schedule_name = 'ANN-ctrl')\n",
    "    myidf.sensor_call(Air_System_Outdoor_Air_Mass_Flow_Rate = 'VAV_1',\n",
    "                      Chiller_Electricity_Rate  = ['DOE REF 1980-2004 WATERCOOLED  CENTRIFUGAL CHILLER 0 1100TONS 0.7KW/TON'],\n",
    "                      Site_Outdoor_Air_Drybulb_Temperature = ['Environment'],\n",
    "                      Zone_Mean_Air_Temperature=['CORE_BOTTOM ZN'],\n",
    "                      Cooling_Coil_Total_Cooling_Rate=['VAV_1 CLG COIL'],\n",
    "                      Lights_Total_Heating_Rate=['CORE_BOTTOM ZN OFFICE WHOLEBUILDING - LG OFFICE LIGHTS'],\n",
    "                      Zone_People_Sensible_Heating_Rate=['CORE_BOTTOM ZN'])\n",
    "    # To update: directly update to original files\n",
    "    myidf.actuator_call(Schedule_Value = [['ANN-ctrl', 'Schedule:Compact']])\n",
    "    # myidf.delete_class('AvailabilityManager:Scheduled')\n",
    "    # myidf.delete_class('AvailabilityManager:NightCycle')\n",
    "    # myidf.delete_class('AvailabilityManagerAssignmentList')\n",
    "    # to update: check why need to be all capital\n",
    "    myidf.set_agent(q_network, input_var)\n",
    "    # myidf.run()\n",
    "    # myidf.save()\n",
    "    # TO ADD: CHECK AGENT\n",
    "    rl_env = dqn(myidf, input_var, q_network, target_network)\n",
    "    rl_env.train()\n",
    "    # a = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:  \n",
    "    try:\n",
    "        print(thinenv.observe())\n",
    "    except _ooep_.TemporaryUnavailableError as e:\n",
    "        pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
